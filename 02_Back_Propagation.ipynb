{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY-L2H3fg4Cg"
      },
      "source": [
        "# Back propagation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN0NzCYGg99f",
        "outputId": "3bd35b4b-3d64-4c89-80de-38a30f244076"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20\n",
            "Training Accuracy:0.6403508771929824\n",
            "Validation Accuracy:0.6923076923076923\n",
            "Epoch 40\n",
            "Training Accuracy:0.8771929824561403\n",
            "Validation Accuracy:0.9230769230769231\n",
            "Epoch 60\n",
            "Training Accuracy:0.8508771929824561\n",
            "Validation Accuracy:0.9230769230769231\n",
            "Epoch 80\n",
            "Training Accuracy:0.9473684210526315\n",
            "Validation Accuracy:0.9230769230769231\n",
            "Epoch 100\n",
            "Training Accuracy:0.9298245614035088\n",
            "Validation Accuracy:0.9230769230769231\n",
            "\n",
            "Testing Accuracy: 0.9130434782608695\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# The sharable Link\n",
        "link = 'https://drive.google.com/file/d/19WL2lcF-1UM1HSDYIa05XtaVinNoUse6'\n",
        "\n",
        "# Get id from link\n",
        "fluff, id = link.split('d/')\n",
        "#print (id)\n",
        "\n",
        "# Get File from Gdrive\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('Iris.csv')\n",
        "\n",
        "iris = pd.read_csv(\"Iris.csv\")\n",
        "iris = iris.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "X = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
        "X = np.array(X)\n",
        "Y = iris.Species\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "Y = one_hot_encoder.fit_transform(np.array(Y).reshape(-1, 1))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1)\n",
        "\n",
        "def InitializeWeights(nodes):\n",
        "       \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n",
        "       layers, weights = len(nodes), []\n",
        "       for i in range(1, layers):\n",
        "              w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)] for j in range(nodes[i])]\n",
        "              weights.append(np.matrix(w))\n",
        "       return weights\n",
        "\n",
        "def ForwardPropagation(x, weights, layers):\n",
        "       activations, layer_input = [x], x\n",
        "       for j in range(layers):\n",
        "              activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
        "              activations.append(activation)\n",
        "              layer_input = np.append(1, activation)               # Augment with bias\n",
        "       return activations\n",
        "\n",
        "def BackPropagation(y, activations, weights, layers):\n",
        "       outputFinal = activations[-1]\n",
        "       error = np.matrix(y - outputFinal)               # Error at output\n",
        "       for j in range(layers, 0, -1):\n",
        "              currActivation = activations[j]\n",
        "              if(j > 1):\n",
        "                     # Augment previous activation\n",
        "                     prevActivation = np.append(1, activations[j-1])\n",
        "              else:\n",
        "                     # First hidden layer, prevActivation is input (without bias)\n",
        "                     prevActivation = activations[0]\n",
        "              delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
        "              weights[j-1] += lr * np.multiply(delta.T, prevActivation)\n",
        "              # Remove bias from weights\n",
        "              w = np.delete(weights[j-1], [0], axis=1)\n",
        "              error = np.dot(delta, w)                      # Calculate error for current layer\n",
        "       return weights\n",
        "\n",
        "def Train(X, Y, lr, weights):\n",
        "       layers = len(weights)\n",
        "       for i in range(len(X)):\n",
        "              x, y = X[i], Y[i]\n",
        "              x = np.matrix(np.append(1, x))                      # Augment feature vector\n",
        "              activations = ForwardPropagation(x, weights, layers)\n",
        "              weights = BackPropagation(y, activations, weights, layers)\n",
        "       return weights\n",
        "\n",
        "def Sigmoid(x):\n",
        "       return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def SigmoidDerivative(x):\n",
        "       return np.multiply(x, 1-x)\n",
        "\n",
        "def Predict(item, weights):\n",
        "       layers = len(weights)\n",
        "       item = np.append(1, item)                           # Augment feature vector\n",
        "       ##_Forward Propagation_##\n",
        "       activations = ForwardPropagation(item, weights, layers)\n",
        "       outputFinal = activations[-1].A1\n",
        "       index = FindMaxActivation(outputFinal)\n",
        "       # Initialize prediction vector to zeros\n",
        "       y = [0 for i in range(len(outputFinal))]\n",
        "       y[index] = 1                                                  # Set guessed class to 1\n",
        "       return y                                                         # Return prediction vector\n",
        "\n",
        "def FindMaxActivation(output):\n",
        "       \"\"\"Find max activation in output\"\"\"\n",
        "       m, index = output[0], 0\n",
        "       for i in range(1, len(output)):\n",
        "              if(output[i] > m):\n",
        "                     m, index = output[i], i\n",
        "       return index\n",
        "\n",
        "def Accuracy(X, Y, weights):\n",
        "       \"\"\"Run set through network, find overall accuracy\"\"\"\n",
        "       correct = 0\n",
        "       for i in range(len(X)):\n",
        "              x, y = X[i], list(Y[i])\n",
        "              guess = Predict(x, weights)\n",
        "              if(y == guess):\n",
        "                     # Guessed correctly\n",
        "                     correct += 1\n",
        "       return correct / len(X)\n",
        "\n",
        "def NeuralNetwork(X_train, Y_train, X_val=None, Y_val=None, epochs=10, nodes=[],  lr=0.15):\n",
        "       hidden_layers = len(nodes) - 1\n",
        "       weights = InitializeWeights(nodes)\n",
        "       for epoch in range(1, epochs+1):\n",
        "              weights = Train(X_train, Y_train, lr, weights)\n",
        "              if(epoch % 20 == 0):\n",
        "                     print(\"Epoch {}\".format(epoch))\n",
        "                     print(\"Training Accuracy:{}\".format(Accuracy(X_train, Y_train, weights)))\n",
        "                     if X_val.any():\n",
        "                            print(\"Validation Accuracy:{}\".format(Accuracy(X_val, Y_val, weights)))\n",
        "       return weights\n",
        "\n",
        "f = len(X[0]) # Number of features\n",
        "o = len(Y[0]) # Number of outputs / classes\n",
        "\n",
        "layers = [f, 5, 10, o]                      # Number of nodes in layers\n",
        "lr, epochs = 0.15, 100\n",
        "\n",
        "weights = NeuralNetwork(X_train, Y_train, X_val, Y_val, epochs=epochs, nodes=layers, lr=lr);\n",
        "print(\"\\nTesting Accuracy: {}\".format(Accuracy(X_test, Y_test, weights)))\n",
        "\n",
        "\n",
        "\n",
        "print(\"Confusion Matrix\")\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "print(\"ROC Curve\") \n",
        "\n",
        "# Compute ROC curve and ROC area for each class\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "roc_auc = dict()\n",
        "for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(Y_test[:, i], Y_score[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and ROC area\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(\n",
        "    fpr[2],\n",
        "    tpr[2],\n",
        "    color=\"darkorange\",\n",
        "    lw=lw,\n",
        "    label=\"ROC curve (area = %0.2f)\" % roc_auc[2],\n",
        ")\n",
        "plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver operating characteristic example\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "algo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit (windows store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "48e4ea11381a31c2d275b6c719b15ddb9313194b71994cea782ec5a9fea096e0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
